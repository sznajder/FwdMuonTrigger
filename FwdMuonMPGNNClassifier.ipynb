{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:pytorch]",
      "language": "python",
      "name": "conda-env-pytorch-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "name": "FwdMuonMPGNNClassifier.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "jxFBp9ERwT5W"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sznajder/FwdMuonTrigger/blob/master/FwdMuonMPGNNClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vclyua3cwT4r",
        "colab_type": "text"
      },
      "source": [
        "# Message Passing GNN (MPGNN) for SEGMENT classification\n",
        "\n",
        "### Based on:\n",
        "\n",
        "https://github.com/jmduarte/gnn-fpga/blob/master/README.md\n",
        "\n",
        "https://github.com/jmduarte/heptrkx-gnn-tracking/blob/master/README.md\n",
        "\n",
        "https://github.com/jmduarte/gnn-fpga/blob/master/gnn/MPNN_HitClassifier.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43wElIHTwT4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# System imports\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import os\n",
        "import sys\n",
        "import multiprocessing as mp\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# Externals\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csr_matrix, find\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.spatial import cKDTree\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Torch imports\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount google drive on remote Colab machine\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "sys.path.append('gdrive/My Drive/Colab Notebooks')\n",
        "\n",
        "!ls 'gdrive/My Drive/Colab Notebooks/Data'\n",
        "data_dir = 'gdrive/My Drive/Colab Notebooks/Data'\n",
        "\n",
        "# Input and Output files and events to read\n",
        "infile = data_dir+'/graphs.npz'\n",
        "events_start=0\n",
        "events_end=100\n",
        "\n",
        "\n",
        "# Local imports\n",
        "#from estimator import Estimator\n",
        "#from acts import process_hits_files, select_barrel_hits\n",
        "\n",
        "#%matplotlib notebook\n",
        "#%matplotlib ipympl\n",
        "%matplotlib inline\n",
        "\n",
        "# Training concurrency\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = '4'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "cuda = False\n",
        "\n",
        "if cuda:\n",
        "    np_to_torch = lambda x, volatile=False: (\n",
        "        Variable(torch.from_numpy(x.astype(np.float32)), volatile=volatile).cuda())\n",
        "else:\n",
        "    np_to_torch = lambda x, volatile=False: (\n",
        "        Variable(torch.from_numpy(x.astype(np.float32)), volatile=volatile))\n",
        "\n",
        "torch_to_np = lambda x: x.cpu().data.numpy()\n",
        "\n",
        "# Graph is a namedtuple of (X, Ri, Ro, y) for convenience\n",
        "feature_names = ['vh_sim_r', 'vh_sim_phi', 'vh_sim_z']\n",
        "feature_scale = np.array([1000., 180. / 6., 1000.])\n",
        "#Graph = namedtuple('Graph', ['X', 'Ri', 'Ro', 'y'])\n",
        "Graph = namedtuple('Graph', ['X', 'Ri', 'Ro', 'y_hits', 'y_segs'])\n",
        "\n",
        "# Sparse graph uses the indices for the Ri, Ro matrices\n",
        "SparseGraph = namedtuple('SparseGraph',['X', 'Ri_rows', 'Ri_cols', 'Ro_rows', 'Ro_cols', 'y'])\n",
        "\n",
        "def graph_to_sparse(graph):\n",
        "    Ri_rows, Ri_cols = graph.Ri.nonzero()\n",
        "    Ro_rows, Ro_cols = graph.Ro.nonzero()\n",
        "    return dict(X=graph.X, y=graph.y,\n",
        "                Ri_rows=Ri_rows, Ri_cols=Ri_cols,\n",
        "                Ro_rows=Ro_rows, Ro_cols=Ro_cols)\n",
        "\n",
        "def sparse_to_graph(X, Ri_rows, Ri_cols, Ro_rows, Ro_cols, y, dtype=np.uint8):\n",
        "    n_nodes, n_edges = X.shape[0], Ri_rows.shape[0]\n",
        "    Ri = np.zeros((n_nodes, n_edges), dtype=dtype)\n",
        "    Ro = np.zeros((n_nodes, n_edges), dtype=dtype)\n",
        "    Ri[Ri_rows, Ri_cols] = 1\n",
        "    Ro[Ro_rows, Ro_cols] = 1\n",
        "    return Graph(X, Ri, Ro, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rysbAgzhQyOz",
        "colab_type": "text"
      },
      "source": [
        "## PYTORCH module implementing a Message Passing GNN\n",
        "\n",
        "https://github.com/jmduarte/gnn-fpga/blob/master/gnn/model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVQJbkxBQ7Lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This module implements the PyTorch modules that define the\n",
        "message-passing graph neural networks for hit or segment classification.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "##############################################################\n",
        "\n",
        "class EdgeNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    A module which computes weights for edges of the graph.\n",
        "    For each edge, it selects the associated nodes' features\n",
        "    and applies some fully-connected network layers with a final\n",
        "    sigmoid activation.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=8, hidden_activation=nn.Tanh):\n",
        "        super(EdgeNetwork, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim*2, hidden_dim),\n",
        "            hidden_activation(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid())\n",
        "    def forward(self, X, Ri, Ro):\n",
        "        # Select the features of the associated nodes\n",
        "        bo = torch.bmm(Ro.transpose(1, 2), X)\n",
        "        bi = torch.bmm(Ri.transpose(1, 2), X)\n",
        "        B = torch.cat([bo, bi], dim=2)\n",
        "        # Apply the network to each edge\n",
        "        return self.network(B).squeeze(-1)\n",
        "\n",
        "##############################################################\n",
        "\n",
        "class NodeNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    A module which computes new node features on the graph.\n",
        "    For each node, it aggregates the neighbor node features\n",
        "    (separately on the input and output side), and combines\n",
        "    them with the node's previous features in a fully-connected\n",
        "    network to compute the new features.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, hidden_activation=nn.Tanh):\n",
        "        super(NodeNetwork, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim*3, output_dim),\n",
        "            hidden_activation(),\n",
        "            nn.Linear(output_dim, output_dim),\n",
        "            hidden_activation())\n",
        "    def forward(self, X, e, Ri, Ro):\n",
        "        bo = torch.bmm(Ro.transpose(1, 2), X)\n",
        "        bi = torch.bmm(Ri.transpose(1, 2), X)\n",
        "        Rwo = Ro * e[:,None]\n",
        "        Rwi = Ri * e[:,None]\n",
        "        mi = torch.bmm(Rwi, bo)\n",
        "        mo = torch.bmm(Rwo, bi)\n",
        "        M = torch.cat([mi, mo, X], dim=2)\n",
        "        return self.network(M)\n",
        "\n",
        "##############################################################\n",
        "\n",
        "class SegmentClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Segment classification graph neural network model.\n",
        "    Consists of an input network, an edge network, and a node network.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=2, hidden_dim=8, n_iters=3, hidden_activation=nn.Tanh):\n",
        "        super(SegmentClassifier, self).__init__()\n",
        "        self.n_iters = n_iters\n",
        "        # Setup the input network\n",
        "        self.input_network = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            hidden_activation())\n",
        "        # Setup the edge network\n",
        "        self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
        "                                        hidden_activation)\n",
        "        # Setup the node layers\n",
        "        self.node_network = NodeNetwork(input_dim+hidden_dim, hidden_dim,\n",
        "                                        hidden_activation)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Apply forward pass of the model\"\"\"\n",
        "        X, Ri, Ro = inputs\n",
        "        # Apply input network to get hidden representation\n",
        "        H = self.input_network(X)\n",
        "        # Shortcut connect the inputs onto the hidden representation\n",
        "        H = torch.cat([H, X], dim=-1)\n",
        "        # Loop over iterations of edge and node networks\n",
        "        for i in range(self.n_iters):\n",
        "            # Apply edge network\n",
        "            e = self.edge_network(H, Ri, Ro)\n",
        "            # Apply node network\n",
        "            H = self.node_network(H, e, Ri, Ro)\n",
        "            # Shortcut connect the inputs onto the hidden representation\n",
        "            H = torch.cat([H, X], dim=-1)\n",
        "        # Apply final edge network\n",
        "        return self.edge_network(H, Ri, Ro)\n",
        "\n",
        "\n",
        "##############################################################\n",
        "'''\n",
        "class NodeClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A message-passing graph neural network model which performs\n",
        "    binary classification of nodes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=4, hidden_dim=8, n_iters=1, hidden_activation=nn.Tanh):\n",
        "        super(NodeClassifier, self).__init__()\n",
        "        self.n_iters = n_iters\n",
        "        # Setup the input network\n",
        "        self.input_network = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            hidden_activation())\n",
        "        # Setup the edge network\n",
        "        self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim, hidden_activation)\n",
        "        # Setup the node layers\n",
        "        self.node_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, hidden_activation)\n",
        "        # Setup the output network\n",
        "        self.output_network = nn.Sequential(\n",
        "            nn.Linear(input_dim+hidden_dim, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Apply forward pass of the model\"\"\"\n",
        "        X, Ri, Ro = inputs\n",
        "        # Apply input network to get hidden representation\n",
        "        H = self.input_network(X)\n",
        "        # Shortcut connect the inputs onto the hidden representation\n",
        "        H = torch.cat([H, X], dim=-1)\n",
        "        # Loop over iterations of edge and node networks\n",
        "        for i in range(self.n_iters):\n",
        "            # Apply edge network\n",
        "            e = self.edge_network(H, Ri, Ro)\n",
        "            # Apply node network\n",
        "            H = self.node_network(H, e, Ri, Ro)\n",
        "            # Shortcut connect the inputs onto the hidden representation\n",
        "            H = torch.cat([H, X], dim=-1)\n",
        "        # Apply final output network\n",
        "        return self.output_network(H).squeeze(-1)\n",
        "'''\n",
        "################################################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_VnEldJRHla",
        "colab_type": "text"
      },
      "source": [
        "## PYTORCH module implementing the Estimator\n",
        "\n",
        "https://github.com/jmduarte/gnn-fpga/blob/master/gnn/estimator.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx4_Cv00RNU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This module contains the Estimator class implementation which provides\n",
        "code for doing the training of a PyTorch model.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import shutil \n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "def logger(s):\n",
        "    \"\"\"Simple logger function which prints date/time\"\"\"\n",
        "    print(datetime.now(), s)\n",
        "\n",
        "class Estimator():\n",
        "    \"\"\"Estimator class\"\"\"\n",
        "\n",
        "    def __init__(self, model, loss_func, opt='Adam',\n",
        "                 train_losses=None, valid_losses=None,\n",
        "                 cuda=False, l1=0.):\n",
        "\n",
        "        self.model = model\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        self.loss_func = loss_func\n",
        "        if opt == 'Adam':\n",
        "            self.optimizer = torch.optim.Adam(self.model.parameters())\n",
        "        elif opt == 'SGD':\n",
        "            self.optimizer = torch.optim.SGD(self.model.parameters())\n",
        "\n",
        "        self.train_losses = train_losses if train_losses is not None else []\n",
        "        self.valid_losses = valid_losses if valid_losses is not None else []\n",
        "        self.l1 = l1\n",
        "\n",
        "        logger('Model: \\n%s' % model)\n",
        "        logger('Parameters: %i' %\n",
        "               sum(param.numel() for param in model.parameters()))\n",
        "\n",
        "    def l1_penalty(self, arr):\n",
        "        return torch.abs(arr).sum()\n",
        "        \n",
        "    def training_step(self, inputs, targets):\n",
        "        \"\"\"Applies single optimization step on batch\"\"\"\n",
        "        self.model.zero_grad()\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        node_weights = [layer.weight for layer in self.model.node_network.network if hasattr(layer, 'weight')]\n",
        "        edge_weights = [layer.weight for layer in self.model.edge_network.network if hasattr(layer, 'weight')]\n",
        "        l1_regularization = self.l1 * sum([self.l1_penalty(arr) for arr in node_weights]) + self.l1 * sum([self.l1_penalty(arr) for arr in edge_weights])\n",
        "        loss = self.loss_func(outputs, targets) + l1_regularization \n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss\n",
        "\n",
        "    def save_checkpoint(self, state, is_best, filename='checkpoint.pt'):\n",
        "#        directory = os.path.dirname(filename)\n",
        "        directory = data_dir\n",
        "        try:\n",
        "            os.stat(directory)\n",
        "        except:\n",
        "            os.mkdir(directory)\n",
        "        torch.save(state, filename)\n",
        "        if is_best:\n",
        "            bestfilename = directory+'/model_best.pt'\n",
        "            shutil.copyfile(filename, bestfilename)\n",
        "            \n",
        "    def load_checkpoint(self, filename='checkpoint.pt'):\n",
        "        checkpoint = torch.load(filename)\n",
        "        self.model.load_state_dict(checkpoint['state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        self.valid_losses = checkpoint['valid_losses']\n",
        "        self.train_losses = checkpoint['train_losses']\n",
        "    \n",
        "    def fit_gen(self, train_generator, n_batches=1, n_epochs=1,\n",
        "                valid_generator=None, n_valid_batches=1, verbose=0, \n",
        "                filename='checkpoint.pt'):\n",
        "        \"\"\"Runs batch training for a number of specified epochs.\"\"\"\n",
        "        epoch_start = len(self.train_losses)\n",
        "        epoch_end = epoch_start + n_epochs\n",
        "        if len(self.valid_losses) > 0:\n",
        "            best_valid_loss = self.valid_losses[-1]\n",
        "        else:\n",
        "            best_valid_loss = 99999999\n",
        "        for i in range(epoch_start, epoch_end):\n",
        "            logger('Epoch %i' % i)\n",
        "            start_time = timer()\n",
        "            sum_loss = 0\n",
        "\n",
        "            # Train the model\n",
        "            self.model.train()\n",
        "            \n",
        "            for j in range(n_batches):\n",
        "                batch_input, batch_target = next(train_generator)\n",
        "                batch_loss = (self.training_step(batch_input, batch_target)\n",
        "                              .cpu().data.item())\n",
        "                sum_loss += batch_loss\n",
        "                if verbose > 0:\n",
        "                    logger('  Batch %i loss %f' % (j, batch_loss))\n",
        "            end_time = timer()\n",
        "            avg_loss = sum_loss / n_batches\n",
        "            self.train_losses.append(avg_loss)\n",
        "            logger('  training loss %.3g time %gs' %\n",
        "                   (avg_loss, (end_time - start_time)))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Evaluate the model on the validation set\n",
        "                if (valid_generator is not None) and (n_valid_batches > 0):\n",
        "                    self.model.eval()\n",
        "                    valid_loss = 0\n",
        "                    for j in range(n_valid_batches):\n",
        "                        valid_input, valid_target = next(valid_generator)\n",
        "                        valid_loss += (self.loss_func(self.model(valid_input), valid_target)\n",
        "                                       .cpu().data.item())\n",
        "                    valid_loss = valid_loss / n_valid_batches\n",
        "                    self.valid_losses.append(valid_loss)\n",
        "                    logger('  validate loss %.3g' % valid_loss)\n",
        "                \n",
        "                    #Save model checkpoint - modified\n",
        "                    logger(' save checkpoint') \n",
        "                    is_best = valid_loss < best_valid_loss\n",
        "                    best_valid_loss = min(valid_loss, best_valid_loss)\n",
        "                    self.save_checkpoint({\n",
        "                        'epoch': i + 1,\n",
        "                        'state_dict': self.model.state_dict(),\n",
        "                        'best_valid_loss': best_valid_loss,\n",
        "                        'valid_losses': self.valid_losses,\n",
        "                        'train_losses': self.train_losses,\n",
        "                        'optimizer' : self.optimizer.state_dict(),\n",
        "                    }, is_best, filename=filename)\n",
        "\n",
        "    def predict(self, generator, n_batches, concat=True):\n",
        "        with torch.no_grad():  \n",
        "            self.model.eval()\n",
        "            outputs = []\n",
        "            for j in range(n_batches):\n",
        "                test_input, test_target = next(generator)\n",
        "                outputs.append(self.model(test_input))\n",
        "            if concat:\n",
        "                outputs = torch.cat(outputs)\n",
        "            return outputs\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxFBp9ERwT5W",
        "colab_type": "text"
      },
      "source": [
        "## Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jU5ee5RwT5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(X, Ri, Ro, y, n_samples=1, batch_size=1, train=True):\n",
        "    volatile = not train\n",
        "    batch_idxs = np.arange(0, n_samples, batch_size)\n",
        "    # Loop over epochs\n",
        "    while True:\n",
        "        # Loop over batches\n",
        "        for j in batch_idxs:\n",
        "#            batch_X  = np_to_torch(  X[j:j+batch_size], volatile=volatile )\n",
        "#            batch_Ri = np_to_torch( Ri[j:j+batch_size], volatile=volatile )\n",
        "#            batch_Ro = np_to_torch( Ro[j:j+batch_size], volatile=volatile )\n",
        "#            batch_y  = np_to_torch(  y[j:j+batch_size], volatile=volatile )\n",
        " \n",
        "          with torch.set_grad_enabled(train):\n",
        "            batch_X  = np_to_torch(  X[j:j+batch_size] )\n",
        "            batch_Ri = np_to_torch( Ri[j:j+batch_size] )\n",
        "            batch_Ro = np_to_torch( Ro[j:j+batch_size] )\n",
        "            batch_y  = np_to_torch(  y[j:j+batch_size] )\n",
        "            batch_inputs = [batch_X, batch_Ri, batch_Ro]\n",
        "            yield batch_inputs, batch_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIy95GB1YjJ6",
        "colab_type": "text"
      },
      "source": [
        "## Network  Model and Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xKxuGZBwT5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model config\n",
        "#hidden_dim = 64\n",
        "hidden_dim = 16\n",
        "#n_iters = 7\n",
        "n_iters = 5\n",
        "\n",
        "# Training config\n",
        "batch_size = 50\n",
        "n_epochs = 100\n",
        "valid_frac = 0.2\n",
        "test_frac = 0.2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX8HZe-IbXJd",
        "colab_type": "text"
      },
      "source": [
        "## Load and prepare the graphs DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "040oVMpLbazl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load GRAPHS from inputfile\n",
        "#sparse = np.load(infile, allow_pickle=True)\n",
        "#gfile = np.load(infile)\n",
        "#garray = gfile.f.arr_0 # convert file to 2D np.ndarrays\n",
        "import glob\n",
        "filenames =  glob.glob(data_dir+'/graphs/*.npz')\n",
        "\n",
        "# Load the graphs into a list \n",
        "graphs = []\n",
        "for f in filenames:\n",
        "  gfile = np.load(f)\n",
        "#  graph = SparseGraph(**dict(gfile.items()))\n",
        "  graph = Graph(**dict(gfile.items()))\n",
        "  graphs.append(graph)\n",
        "\n",
        "# Get the matrix sizes in this batch\n",
        "n_graphs = len(graphs)\n",
        "n_features = graphs[0].X.shape[1] \n",
        "n_nodes    = np.array([g.X.shape[0] for g in graphs])\n",
        "n_edges    = np.array([g.y_segs.shape[0] for g in graphs])\n",
        "max_nodes = n_nodes.max()\n",
        "max_edges = n_edges.max()\n",
        "\n",
        "\n",
        "print(\"n_graphs\",n_graphs)\n",
        "print(\"n_features\",n_features)\n",
        "print(\"n_nodes\",n_nodes)\n",
        "print(\"n_edges\",n_edges)\n",
        "print(\"max_nodes\",max_nodes)\n",
        "print(\"max_edges\",max_edges)\n",
        "\n",
        "# Define GRAPH tensors for the full dataset\n",
        "n_samples = n_graphs\n",
        "X  = np.zeros((n_samples, max_nodes, n_features), dtype=np.float32) # node features \n",
        "Ri = np.zeros((n_samples, max_nodes, max_edges) , dtype=np.float32)  # adjacency matrix\n",
        "Ro = np.zeros((n_samples, max_nodes, max_edges) , dtype=np.float32)  #\n",
        "y_hits  = np.zeros((n_samples, max_nodes), dtype=np.float32)             # target label\n",
        "y_segs  = np.zeros((n_samples, max_edges), dtype=np.float32)             # target label\n",
        "\n",
        "# Loop over graphs and fill the tensors ( with event # indexed  by i )\n",
        "for i, g in enumerate(graphs):\n",
        "  X[i,  :n_nodes[i]] = g.X \n",
        "  Ri[i, :n_nodes[i], :n_edges[i]] = g.Ri\n",
        "  Ro[i, :n_nodes[i], :n_edges[i]] = g.Ro\n",
        "  y_segs[i,  :n_edges[i]] = g.y_segs                 \n",
        "  y_hits[i,  :n_nodes[i]] = g.y_hits                 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coATokAiZvHF",
        "colab_type": "text"
      },
      "source": [
        "## Partition dataset into TRAIN , TEST and VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSouxwsjwT5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# We round by batch_size to avoid partial batches\n",
        "n_test  = int(n_samples * test_frac)     // batch_size * batch_size\n",
        "n_valid = int(n_samples * valid_frac)    // batch_size * batch_size\n",
        "n_train = (n_samples - n_valid - n_test) // batch_size * batch_size\n",
        "n_train_batches = n_train // batch_size\n",
        "n_valid_batches = n_valid // batch_size\n",
        "n_test_batches  = n_test  // batch_size\n",
        "\n",
        "# Partition the dataset into TEST, VALIDATION and TRAIN \n",
        "(train_X, test_X,  train_Ri, test_Ri,  train_Ro, test_Ro,  train_y, test_y)  = train_test_split(X, Ri, Ro, y_segs, test_size=n_test)\n",
        "(train_X, valid_X, train_Ri, valid_Ri, train_Ro, valid_Ro, train_y, valid_y) = train_test_split(X, Ri, Ro, y_segs, test_size=n_valid)\n",
        "\n",
        "# Prepare the batch samples\n",
        "train_batcher = batch_generator(train_X, train_Ri, train_Ro, train_y, train=True , n_samples=n_train, batch_size=batch_size)\n",
        "valid_batcher = batch_generator(valid_X, valid_Ri, valid_Ro, valid_y, train=False, n_samples=n_valid, batch_size=batch_size)\n",
        "test_batcher  = batch_generator(test_X ,  test_Ri,  test_Ro, test_y , train=False, n_samples=n_test , batch_size=batch_size)\n",
        "\n",
        "print('Graphs shapes:', X.shape , Ri.shape , Ro.shape , y_segs.shape)\n",
        "print('Graphs node features:', feature_names)\n",
        "print(\"n_train, n_valid, n_test  = \" , n_train, \" , \" , n_valid, \" , \" , n_test )\n",
        "print('Train shapes:', train_X.shape , train_Ri.shape , train_Ro.shape , train_y.shape)\n",
        "print('Valid shapes:', valid_X.shape , valid_Ri.shape , valid_Ro.shape , valid_y.shape)\n",
        "print('Test shapes: ', test_X.shape  , test_Ri.shape  , test_Ro.shape  , test_y.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIY5Kr2raUdE",
        "colab_type": "text"
      },
      "source": [
        "## Construct the GNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiY4tHhQwT5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct the model\n",
        "#model = EdgeClassifier(input_dim=n_features, hidden_dim=hidden_dim, n_iters=n_iters)\n",
        "model = SegmentClassifier(input_dim=n_features, hidden_dim=hidden_dim, n_iters=n_iters) \n",
        "loss_func = nn.BCELoss()\n",
        "estim = Estimator(model, loss_func=loss_func, cuda=cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27DD1v6dakaO",
        "colab_type": "text"
      },
      "source": [
        "## Train the GNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGZU0dEvwT5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estim.fit_gen(train_batcher, n_batches=n_train_batches, n_epochs=n_epochs,valid_generator=valid_batcher, n_valid_batches=n_valid_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE8UBMojwT5r",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate NN Training and Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yIu7zcCoCGRE",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score , precision_score , recall_score , precision_recall_curve , roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use('default')\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.legend(fontsize=10)\n",
        "SMALL_SIZE = 8\n",
        "MEDIUM_SIZE = 10\n",
        "BIGGER_SIZE = 12\n",
        "LINE_WIDTH = 2\n",
        "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "# plot loss vs epoch\n",
        "ax = plt.subplot(3, 2, 1)\n",
        "ax.plot(estim.train_losses, label='training set',lw=LINE_WIDTH)\n",
        "ax.plot(estim.valid_losses, label='validation set',lw=LINE_WIDTH)\n",
        "#ax.set_ylim([0, 1])\n",
        "ax.legend(loc=\"upper right\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "\n",
        "'''\n",
        "# plot accuracy vs epoch\n",
        "ax = plt.subplot(3, 2, 1)\n",
        "ax.plot(estim.train_accuracy, label=='training set',lw=LINE_WIDTH)\n",
        "ax.plot(estim.valid_accuracy, label='validation set',lw=LINE_WIDTH)\n",
        "#ax.set_ylim([0, 1])\n",
        "ax.legend(loc=\"upper right\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')\n",
        "'''\n",
        "\n",
        "\n",
        "# Evaluate on TEST data\n",
        "test_outputs = estim.predict(test_batcher, n_test_batches, concat=False)\n",
        "test_pred = torch_to_np(estim.predict(test_batcher, n_test_batches))\n",
        "\n",
        "flat_y = test_y.flatten()\n",
        "flat_pred = test_pred.flatten()\n",
        "\n",
        "# Compute the ROC and Precisio X Recall curve\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(flat_y, flat_pred)\n",
        "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
        "p, r, t = sklearn.metrics.precision_recall_curve(flat_y, flat_pred)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# NN discriminatnt CUT \n",
        "cut=0.5\n",
        "\n",
        "# Transform predictions into a array of entries 0,1 depending if prdiction is above cut\n",
        "y_pred = flat_y.copy()\n",
        "y_pred[y_pred >= cut]=1\n",
        "y_pred[y_pred < cut]=0\n",
        "y_true = flat_y.copy()\n",
        "w_test = np.ones(len(y_pred))\n",
        "\n",
        "print(\"y_true.shape\",y_true.shape)\n",
        "print(\"y_pred.shape\",y_pred.shape)\n",
        "print(\"w_test.shape\",w_test.shape)\n",
        "\n",
        "print(\"y_true\",y_true)\n",
        "print(\"y_pred\",y_pred)\n",
        "print(\"w_test\",w_test)\n",
        "\n",
        "accuracy  = accuracy_score(y_true, y_pred, sample_weight=w_test)\n",
        "precision = precision_score(y_true, y_pred, sample_weight=w_test)\n",
        "recall    = recall_score(y_true, y_pred, sample_weight=w_test)\n",
        "print('DNN output cut:      %.4f' % cut)\n",
        "print('Accuracy:            %.4f' % accuracy)\n",
        "print('Precision/Purity:  %.4f' % precision)\n",
        "print('Sensitivity/Recall/TPR/Signal Efficiency: %.4f' % recall)\n",
        "#print('Specificity/Selectivity/TNR/Background Efficiency: %.4f' % recall)\n",
        "\n",
        " \n",
        "\n",
        "# Plot ROC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "ax = plt.subplot(3, 2, 3)\n",
        "ax.plot(fpr, tpr, lw=LINE_WIDTH, color='cyan', label='auc = %.3f' % (roc_auc))\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', color='k', label='random chance')\n",
        "ax.set_xlim([0, 1.0])\n",
        "ax.set_ylim([0, 1.0])\n",
        "ax.set_xlabel('False Positive Rate(FPR)')\n",
        "ax.set_ylabel('True Positive Rate(TPR)')\n",
        "#ax.set_title('Receiver Operating Curve(ROC)')\n",
        "ax.legend(loc=\"lower right\")\n",
        "\n",
        "# Get model prediction for signal and background \n",
        "Y_sig = y_pred[(y_true).astype(int)]\n",
        "Y_bkg = y_pred[(1-y_true).astype(int)]\n",
        "\n",
        "ax = plt.subplot(3, 2, 4)\n",
        "X = np.linspace(0.0, 1.0, 100)\n",
        "hist_sig = ax.hist(Y_sig, bins=X, label='sig',histtype='step',lw=LINE_WIDTH)\n",
        "hist_bkg = ax.hist(Y_bkg, bins=X, label='bkg',histtype='step',lw=LINE_WIDTH)\n",
        "#ax.hist(Y_train_val, bins=X, label='bkg',histtype='step')\n",
        "ax.set_xlabel('DNN Output')\n",
        "ax.legend(prop={'size': 10})\n",
        "\n",
        "\n",
        "# Plot Eff x Purity\n",
        "\n",
        "ax = plt.subplot(3, 2, 5)\n",
        "ax.plot(t, p[:-1], label='purity', lw=LINE_WIDTH)\n",
        "ax.plot(t, r[:-1], label='efficiency', lw=LINE_WIDTH)\n",
        "ax.set_xlabel('Cut on model score')\n",
        "ax.tick_params(width=2, grid_alpha=0.5)\n",
        "ax.legend()\n",
        "\n",
        "ax = plt.subplot(3, 2, 6)\n",
        "ax.plot(t,p[:-1]*r[:-1], lw=LINE_WIDTH)\n",
        "ax.set_xlabel('Cut on model score')\n",
        "ax.set_ylabel('Purity*Efficiency')\n",
        "ax.tick_params(width=2, grid_alpha=0.5)\n",
        "\n",
        "# Show plots\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvpOfvzXwT5y",
        "colab_type": "text"
      },
      "source": [
        "## Visualize some samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2Ox4tJl7wT5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drawGraph(X, Ri, Ro, y, pred): \n",
        "    # Select the i/o node features for each segment    \n",
        "    # Prepare the figure\n",
        " \n",
        "    fig, (ax0,ax1) = plt.subplots(1, 2, figsize=(12,8))\n",
        "#    cmap = plt.get_cmap('bwr_r')\n",
        "\n",
        "    # Rescale for plotting purposes\n",
        "    X=X*feature_scale\n",
        "    # HITS features \n",
        "    R=X[:,0]\n",
        "    Phi=(np.pi/180.)*X[:,1]\n",
        "    Z=X[:,2] # Don't save isMuon X[:,3] component in graph feature\n",
        "    XX=R*np.cos(Phi)\n",
        "    YY=R*np.sin(Phi)\n",
        "\n",
        "    # Transform 0 and 1 labels into color list using the dictionary \n",
        "    colordic={1:'blue' , 0:'red'}\n",
        "#    cl=[colordic.get(n) for n in X[:,3]] # use the hit target value for color\n",
        "\n",
        "    # Plot the hits\n",
        "    ax0.scatter(XX,YY, s=100., color='black' )\n",
        "    ax1.scatter(Z,R, s=100., color='black' )\n",
        "    \n",
        "    # Get the hits indices from the SGMENTS arrays\n",
        "    idx_i = find(np.rot90(Ri))[1]\n",
        "    idx_o = find(np.rot90(Ro))[1]\n",
        "  \n",
        "    # Reverse to get correct hits order as in dh_hits \n",
        "    idx_i=idx_i[::-1]\n",
        "    idx_o=idx_o[::-1]\n",
        "\n",
        "    # Get SEGMENTS begin and end hits coordinates\n",
        "    R_i=X[idx_i,0]\n",
        "    Phi_i=(np.pi/180.)*X[idx_i,1]\n",
        "    Z_i=X[idx_i,2]\n",
        "    X_i=R_i*np.cos(Phi_i)\n",
        "    Y_i=R_i*np.sin(Phi_i)\n",
        "  \n",
        "    R_o=X[idx_o,0]\n",
        "    Phi_o=(np.pi/180.)*X[idx_o,1]\n",
        "    Z_o=X[idx_o,2]\n",
        "    X_o=R_o*np.cos(Phi_o)\n",
        "    Y_o=R_o*np.sin(Phi_o)\n",
        "  \n",
        "    # Create a list of SEGMENTS colors \n",
        "#    cl=[colordic.get(n) for n in y]\n",
        "    cl=[colordic.get(np.round((n-cut+0.5),0)) for n in pred]\n",
        "\n",
        "    # Plot segments\n",
        "\n",
        "    for j in range(len(X_i)):\n",
        "      ax0.plot([X_i[j], X_o[j]], [Y_i[j], Y_o[j]], '-', color=cl[j])\n",
        "      ax1.plot([Z_i[j], Z_o[j]], [R_i[j], R_o[j]], '-', color=cl[j])\n",
        "\n",
        "\n",
        "    # Show plots\n",
        "    ax0.set_xlabel('X')\n",
        "    ax0.set_ylabel('Y')\n",
        "    ax1.set_xlabel('Z')\n",
        "    ax1.set_ylabel('R')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Loop to draw one graph per event\n",
        "\n",
        "for i in range(n_test):\n",
        "    X = test_X[i,:,:] \n",
        "    Ri = test_Ri[i,:]\n",
        "    Ro = test_Ro[i,:]\n",
        "#    pred = test_pred[i].squeeze(0)\n",
        "    pred = test_pred[i,:]\n",
        "    y = test_y[i,:]\n",
        "\n",
        "    print('Y =',y)\n",
        "    print('PRED =',pred)\n",
        "    print('--------------------------------------')\n",
        "\n",
        "    print('accuracy %.3f, precision %.3f, recall %.3f' % (\n",
        "        sklearn.metrics.accuracy_score(y, pred>cut),\n",
        "        sklearn.metrics.precision_score(y, pred>cut),\n",
        "        sklearn.metrics.recall_score(y, pred>cut)))\n",
        "    drawGraph(X, Ri, Ro, y , pred);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}